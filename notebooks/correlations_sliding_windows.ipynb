{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "##### DATA ####\n",
    "\n",
    "homedir = '' # enter your homedir here\n",
    "projectdir = homedir + '' # add projectdir\n",
    "\n",
    "bamdir     = projectdir + 'ChIPseq/final_bam/dedup/' # you can download bamfiles from Zenodo: 10.5281/zenodo.1480328\n",
    "\n",
    "name2bamfile = {}\n",
    "name2bamfile['H3K4me2_a']  = bamdir + '1358_lane7-index13.mapped2.Fol2.bwa_aln.samtools_sort.picard_dedup.bam'\n",
    "name2bamfile['H3K4me2_b']  = bamdir + 'HTS806_lane5-index0004.mapped2.Fol2.bwa_aln.samtools_sort.picard_dedup.bam'\n",
    "name2bamfile['H3K27me3_a'] = bamdir + '1360_lane7-index15.mapped2.Fol2.bwa_aln.samtools_sort.picard_dedup.bam'\n",
    "name2bamfile['H3K27me3_b'] = bamdir + '808_lane5-index0006.mapped2.Fol2.bwa_aln.samtools_sort.picard_dedup.bam'\n",
    "\n",
    "name2bedfile = {}\n",
    "name2bedfile['GENES']         = projectdir + 'GENES/fusarium_oxysporum_f._sp._lycopersici_4287_2_transcripts.gtf'\n",
    "name2bedfile['REPEATS']       = projectdir + 'REPEATS/Fol4287_Repeats.bed' \n",
    "name2bedfile['SNPs_VCG030']   = projectdir + 'filteredSNPs/asBed/vcg030re.annot.pass.nodup.bed'\n",
    "name2bedfile['SNPs_CladeIII'] = projectdir + 'filteredSNPs/asBed/cladeIIIvcg030re.annot.pass.nodup.bed'\n",
    "\n",
    "value_per_gene_dir = projectdir + 'values_per_gene/'\n",
    "name2gene2value = {}\n",
    "name2gene2value['dNdS']  = value_per_gene_dir + 'dN_dS_values.filtered.perGene.tab'\n",
    "name2gene2value['dN']    = value_per_gene_dir + 'dN_values.filtered.perGene.tab'\n",
    "name2gene2value['dS']    = value_per_gene_dir + 'dS_values.filtered.perGene.tab'\n",
    "\n",
    "name2gene2value['invitro_RPKM']   = value_per_gene_dir + 'in_vitro_RPKM.tab'\n",
    "name2gene2value['inplanta_RPKM']  = value_per_gene_dir + 'in_planta_RPKM.tab'\n",
    "name2gene2value['log2foldChange'] = value_per_gene_dir + 'log2foldChange.tab'\n",
    "\n",
    "print('Chip-seq:')\n",
    "for name in name2bamfile.keys():\n",
    "    print(name, '\\t', name2bamfile[name])\n",
    "print('\\n')\n",
    "print('Gene- and repeat density:')\n",
    "for name in name2bedfile.keys():\n",
    "    print(name, '\\t', name2bedfile[name])\n",
    "print('\\n')\n",
    "print ('Value per gene:')\n",
    "for name in name2gene2value.keys():\n",
    "    print(name, '\\t', name2gene2value[name])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correlations between genome characteristics\n",
    "\n",
    "We have different characteristics mapped to the genome:\n",
    "\n",
    "* gene-properties\n",
    "    - relative expression level\n",
    "    - dN\n",
    "    - dS\n",
    "    \n",
    "* genome properties\n",
    "    - read density ChIP-seq experiments\n",
    "    - gene density\n",
    "    - repeat density/copynumber\n",
    "\n",
    "Some of these properties are interdependent, e.g. we may find H3K27Me3 in regions where gene are overexpressed in planta because this marker is instrumental in gene regulation. Similarly, we may find that regions that are enriched for H3K27Me3 are more divergent when compared to other species, because either genes are under less negative selection because they are not expressed except during infection, or because the de novo mutation rate is higher in these regions because they are less accessible to DNA repair machinery.\n",
    "\n",
    "To answer these questions, we want to determine which characterics 'go together' *most strongly*. We divide the genome into windows, calculated average values for properties in these windows. Here, we calculate correlation coefficients T (Kendall's Tau because we can not assume that characteristics are normally distributed and thus can not use Pearson) between all characteristics and use these as distance measures (1-T) for clustering.\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Density or average value per window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#make one huge table with all values per window\n",
    "codedir = homedir+'' #enter the folder where you cloned the repo\n",
    "\n",
    "import sys\n",
    "sys.path.append(codedir + 'tools/')\n",
    "import window_tools\n",
    "\n",
    "windows_fname  = projectdir + 'windows/Fol4287broad.10000_windows.bed'\n",
    "wname = '10000'\n",
    "contig2windows = {}\n",
    "for line in open(windows_fname).readlines():\n",
    "    contig, start, end = line.strip().split()\n",
    "    if contig not in contig2windows: contig2windows[contig] = []\n",
    "        \n",
    "    window = start+'\\t'+end\n",
    "    contig2windows[contig].append(window)\n",
    "\n",
    "    \n",
    "# BAMFILES\n",
    "all_window2values = {}\n",
    "bamnames = list(name2bamfile.keys())\n",
    "bamnames.sort()\n",
    "names = []\n",
    "for name in bamnames:\n",
    "    contig2window2values = {}\n",
    "    \n",
    "    bam_fname = name2bamfile[name]\n",
    "    density_fname = window_tools.density_bamfile(windows_fname, wname, bam_fname)\n",
    "    for line in open(density_fname).readlines():\n",
    "        contig, start, end, density = line.strip().split()\n",
    "        if contig not in contig2window2values: contig2window2values[contig] = {}\n",
    "        \n",
    "        window = start+'\\t'+end\n",
    "        contig2window2values[contig][window] = density\n",
    "        \n",
    "    all_window2values[name] = contig2window2values\n",
    "    names.append(name)\n",
    "\n",
    "# BEDFILES\n",
    "for name in name2bedfile.keys():\n",
    "    #print(name)\n",
    "    contig2window2values = {}\n",
    "    \n",
    "    bed_fname     = name2bedfile[name]\n",
    "    density_fname = window_tools.density_bedfile(windows_fname, wname, bed_fname)\n",
    "    #print(density_fname)\n",
    "    if density_fname != None:\n",
    "        for line in open(density_fname).readlines():\n",
    "            contig, start, end, overlap = line.strip().split()\n",
    "            if contig not in contig2window2values: contig2window2values[contig] = {}\n",
    "\n",
    "            window = start+'\\t'+end\n",
    "            contig2window2values[contig][window] = overlap\n",
    "\n",
    "        all_window2values[name] = contig2window2values\n",
    "        names.append(name)\n",
    "\n",
    "# FILES WITH A VALUE PER GENE\n",
    "gene_values = list(name2gene2value.keys())\n",
    "gene_values.sort()\n",
    "\n",
    "scaffold2start2gene = window_tools.genebed2dict(projectdir + 'GENES/Fol4287__genes.bed')\n",
    "window2genes        = window_tools.get_window2genes(windows_fname, scaffold2start2gene)\n",
    "for name in gene_values:\n",
    "    \n",
    "    contig2window2values = {}\n",
    "    gene2value_fname     = name2gene2value[name]\n",
    "    density_fname        = window_tools.average_gene_values_per_window(windows_fname, wname, gene2value_fname, window2genes)\n",
    "    for line in open(density_fname).readlines():\n",
    "        data = line.split('\\t')\n",
    "        contig, start, end, mean = data[:4]\n",
    "        if contig not in contig2window2values: contig2window2values[contig] = {}\n",
    "        \n",
    "        window = start+'\\t'+end\n",
    "        contig2window2values[contig][window] = mean\n",
    "        \n",
    "    all_window2values[name] = contig2window2values\n",
    "    names.append(name)\n",
    "print(names)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Write these density into a single file\n",
    "\n",
    "Now we have a 'superdictionary' with all values (densities, averages of genes). We will write this to a file (to go as SOM with the paper), ordered according to the 3-speed genome: core, fast-core, accessory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import plot_tools\n",
    "\n",
    "contiglist = plot_tools.keyword_to_contigslist('Fol4287_3speed', prefix = 'Supercontig_2.', gapsize = 10)\n",
    "\n",
    "# note that this list does not contain unpositioned scaffolds\n",
    "# add unpositioned scaffolds at the end of the list (after a gap)\n",
    "contiglist.append('__GAP')\n",
    "contigset = set(contiglist)\n",
    "for contig in set(contig2windows.keys()).difference(contigset):\n",
    "    contiglist.append(contig)\n",
    "\n",
    "all_values_per_window_fname = projectdir + 'windows/all_values_per_window.tab'\n",
    "outfile = open(all_values_per_window_fname, 'w')\n",
    "header  = 'Supercontig\\tstart\\tend'\n",
    "#print(names)\n",
    "for name in names:\n",
    "    header += '\\t'+name\n",
    "outfile.write(header+'\\n')\n",
    "#print(header)\n",
    "for contig in contiglist:\n",
    "    #print(contig)\n",
    "    if contig[:5] != '__GAP':\n",
    "        \n",
    "        for window in contig2windows[contig]:\n",
    "            line = contig+'\\t'+window\n",
    "            for name in names:\n",
    "                line += '\\t'+all_window2values[name][contig][window]\n",
    "            outfile.write(line+'\\n')\n",
    "        \n",
    "outfile.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Clustering of values and of windows, heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# check versions of scipy (scipy 0.18 has a bug in the clustering algorithm)\n",
    "import scipy\n",
    "print(scipy.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def similarity_matrix_2D__to__distance_matrix_1D(matrix):\n",
    "    distances = []\n",
    "    for row_index, row in enumerate(matrix[:-1]):\n",
    "        for value in row[row_index+1:]:\n",
    "            distances.append(1-value)\n",
    "            \n",
    "    return distances\n",
    "\n",
    "def TEST_similarity_matrix_2D__to__distance_matrix_1D():\n",
    "    matrix = [[1,0.5,-0.3,0.4], [0.5,1,0.2,0.7],[-0.3,0.2, 1,-1.4],[0.4, 0.7, -1.4, 1]]\n",
    "    \n",
    "    print(similarity_matrix_2D__to__distance_matrix_1D(np.array(matrix)))\n",
    "    \n",
    "TEST_similarity_matrix_2D__to__distance_matrix_1D()\n",
    "# must result in: [0.5, 1.3, 0.6, 0.8, 0.3, 2.4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "sns.set_context(\"paper\")\n",
    "\n",
    "from scipy import stats\n",
    "from scipy.spatial import distance\n",
    "from scipy.cluster import hierarchy\n",
    "from sklearn import preprocessing\n",
    "\n",
    "\n",
    "windows2values = pd.read_csv(all_values_per_window_fname, sep = '\\t', header = 0)\n",
    "\n",
    "# Calculate correlations with P values for histone modifications and other characteristics\n",
    "Hmods = ['H3K27me3_a', 'H3K27me3_b', 'H3K4me2_a', 'H3K4me2_b']\n",
    "for Hmod in Hmods:\n",
    "    print(\"_________________________________________________\")\n",
    "    print(\"Kendall's Tau for\",Hmod,\"with GENES\")\n",
    "    tau, Pvalue = stats.kendalltau(windows2values[Hmod], windows2values['GENES'])\n",
    "    print(tau, Pvalue,'\\n')\n",
    "    \n",
    "    print(\"Kendall's Tau for\",Hmod,\"with REPEATS\")\n",
    "    tau, Pvalue = stats.kendalltau(windows2values[Hmod], windows2values['REPEATS'])\n",
    "    print(tau, Pvalue,'\\n')\n",
    "    \n",
    "  \n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Correlation heatmap\n",
    "windows2values = pd.read_csv(all_values_per_window_fname, sep = '\\t', header = 0)\n",
    "windows2values.drop('Supercontig', axis=1, inplace=True)\n",
    "windows2values.drop('start', axis=1, inplace=True)\n",
    "windows2values.drop('end', axis=1, inplace=True)\n",
    "\n",
    "# Pandas deals with missing values correctly, hence we will use pandas to calculate correlations\n",
    "# min_periods is minimum number of values in a column\n",
    "corr_df           = windows2values.corr(method='spearman', min_periods = 20)\n",
    "#print(corr_df)\n",
    "similarity_matrix = corr_df.as_matrix()\n",
    "\n",
    "#convert this similarity matrix into a distance matrix that is suitable for scipy.cluster.hierarchy\n",
    "distance_matrix   = similarity_matrix_2D__to__distance_matrix_1D(similarity_matrix)\n",
    "\n",
    "row_linkage = hierarchy.linkage(distance_matrix, method='average')\n",
    "#print(row_linkage)\n",
    "\n",
    "clst = sns.clustermap(similarity_matrix, row_linkage=row_linkage, col_linkage = row_linkage, vmin = -1.0, vmax = 1.0, cmap = 'RdBu')#RdYlGn')\n",
    "\n",
    "# get correct labeling\n",
    "name_index2name = {}\n",
    "for name_index, name in enumerate(names):\n",
    "    name_index2name[name_index] = name\n",
    "    \n",
    "xlabels_as_index = []\n",
    "for textobject in clst.ax_heatmap.get_xticklabels():\n",
    "    xlabels_as_index.append(int(textobject.get_text()))\n",
    "print(xlabels_as_index)\n",
    "\n",
    "xaxis_labels = []\n",
    "for li in xlabels_as_index:\n",
    "    xaxis_labels.append(name_index2name[li])\n",
    "clst.ax_heatmap.set_xticklabels(xaxis_labels, rotation = 'vertical')\n",
    "\n",
    "ylabels_as_index = []\n",
    "for textobject in clst.ax_heatmap.get_yticklabels():\n",
    "    ylabels_as_index.append(int(textobject.get_text()))\n",
    "print(ylabels_as_index)\n",
    "\n",
    "yaxis_labels = []\n",
    "for li in ylabels_as_index:\n",
    "    yaxis_labels.append(name_index2name[li])\n",
    "clst.ax_heatmap.set_yticklabels(yaxis_labels, rotation = 'horizontal')\n",
    "      \n",
    "        \n",
    "plt.savefig(projectdir + 'windows/HEATMAP_values_per_window__RdBu2.eps')#YlGn.eps')\n",
    "plt.show()\n",
    "                         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# get list of scaffols per category\n",
    "chr_categories = ['core', 'fast-core', 'accessory', 'lineage-specific', 'pathogenicity']\n",
    "cat2chrs = {}\n",
    "\n",
    "cat2chrs['core']             = ['chr01_C','chr02_C','chr04','chr05','chr07','chr08','chr09','chr10',]\n",
    "cat2chrs['fast-core']        = ['chr11','chr12','chr13']\n",
    "cat2chrs['accessory']        = ['chr01_LS', 'chr02_LS', 'chr03P', 'chr03A', 'chr06A','chr06P','chr15','chr14']\n",
    "cat2chrs['lineage-specific'] = ['chr01_LS', 'chr02_LS', 'chr03A', 'chr06A','chr15']\n",
    "cat2chrs['pathogenicity']    = ['chr14', 'chr03P', 'chr06P']\n",
    "\n",
    "chr2scaffolds = {}\n",
    "chr2scaffolds['chr01']    = [14, 1, 27]\n",
    "chr2scaffolds['chr01_C']  = [14, 1]\n",
    "chr2scaffolds['chr01_LS'] = [27]\n",
    "chr2scaffolds['chr02']    = [6,10, 31]\n",
    "chr2scaffolds['chr02_C']  = [6, 10]\n",
    "chr2scaffolds['chr02_LS'] = [31]\n",
    "chr2scaffolds['chr03']    = [47,18,32,7,25]\n",
    "chr2scaffolds['chr03A']   = [32, 7, 25]\n",
    "chr2scaffolds['chr03P']   = [47, 18]\n",
    "chr2scaffolds['chr04']    = [8, 4]\n",
    "chr2scaffolds['chr05']    = [26, 2]\n",
    "chr2scaffolds['chr06']    = [9, 33, 41, 21, 53, 42]\n",
    "chr2scaffolds['chr06A']   = [9, 33]\n",
    "chr2scaffolds['chr06P']   = [41, 21, 53, 42]\n",
    "chr2scaffolds['chr07']    = [5, 13]\n",
    "chr2scaffolds['chr08']    = [3, 29]\n",
    "chr2scaffolds['chr09']    = [11, 17]\n",
    "chr2scaffolds['chr10']    = [20, 15, 45]\n",
    "chr2scaffolds['chr11']    = [35, 12]\n",
    "chr2scaffolds['chr12']    = [19, 23]\n",
    "chr2scaffolds['chr13']    = [16, 39]\n",
    "chr2scaffolds['chr14']    = [22, 43, 51, 36]\n",
    "chr2scaffolds['chr15']    = [37, 38, 24, 28]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "import seaborn as sns\n",
    "sns.set_context(\"paper\")\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from scipy import stats\n",
    "\n",
    "from scipy.spatial import distance\n",
    "from scipy.cluster import hierarchy\n",
    "from sklearn import preprocessing\n",
    "\n",
    "\n",
    "all_values_per_window_fname = projectdir + 'windows/all_values_per_window.tab'\n",
    "allwindows2values = pd.read_csv(all_values_per_window_fname, sep = '\\t', header = 0)\n",
    "\n",
    "\n",
    "for cat in chr_categories:\n",
    "    print(cat)\n",
    "    subset_names = []+names\n",
    "    #filter out windows located on supercontigs that are not in this category\n",
    "    include = []\n",
    "    for chr in cat2chrs[cat]:\n",
    "        for scaff in chr2scaffolds[chr]:\n",
    "            include.append('Supercontig_2.'+str(scaff))\n",
    "            \n",
    "    windows2values = allwindows2values[allwindows2values.Supercontig.isin(include)]\n",
    "    windows2values.drop('Supercontig', axis=1, inplace=True)\n",
    "    windows2values.drop('start', axis=1, inplace=True)\n",
    "    windows2values.drop('end', axis=1, inplace=True)\n",
    "    \n",
    "    if cat == 'accessory' or cat == 'lineage-specific' or cat == 'pathogenicity':\n",
    "        windows2values.drop('dN', axis=1, inplace=True)\n",
    "        windows2values.drop('dS', axis=1, inplace=True)\n",
    "        windows2values.drop('dNdS', axis=1, inplace=True)\n",
    "        subset_names.remove('dN')\n",
    "        subset_names.remove('dS')\n",
    "        subset_names.remove('dNdS')\n",
    "      \n",
    "\n",
    "    # Pandas deals with missing values correctly, hence we will use pandas to calculate correlations\n",
    "    corr_df           = windows2values.corr(method='spearman', min_periods = 20)\n",
    "    similarity_matrix = corr_df.as_matrix()\n",
    "    \n",
    "    #convert this similarity matrix into a distance matrix that is suitable for scipy.cluster.hierarchy\n",
    "    distance_matrix   = similarity_matrix_2D__to__distance_matrix_1D(similarity_matrix)\n",
    "\n",
    "    row_linkage = hierarchy.linkage(distance_matrix, method='average')\n",
    "    #print row_linkage\n",
    "\n",
    "    clst = sns.clustermap(similarity_matrix, row_linkage=row_linkage, col_linkage = row_linkage, vmin = -1.0, vmax = 1.0, cmap = 'RdBu_r')\n",
    "\n",
    "    # get correct labeling\n",
    "    name_index2name = {}\n",
    "    for name_index, name in enumerate(subset_names):      \n",
    "        name_index2name[name_index] = name\n",
    "\n",
    "    xlabels_as_index = []\n",
    "    for textobject in clst.ax_heatmap.get_xticklabels():\n",
    "        xlabels_as_index.append(int(textobject.get_text()))\n",
    "    \n",
    "\n",
    "    xaxis_labels = []\n",
    "    for li in xlabels_as_index:\n",
    "        xaxis_labels.append(name_index2name[li])\n",
    "    clst.ax_heatmap.set_xticklabels(xaxis_labels, rotation = 'vertical')\n",
    "\n",
    "    ylabels_as_index = []\n",
    "    for textobject in clst.ax_heatmap.get_yticklabels():\n",
    "        ylabels_as_index.append(int(textobject.get_text()))\n",
    "    \n",
    "\n",
    "    yaxis_labels = []\n",
    "    for li in ylabels_as_index:\n",
    "        yaxis_labels.append(name_index2name[li])\n",
    "    clst.ax_heatmap.set_yticklabels(yaxis_labels, rotation = 'horizontal')\n",
    "\n",
    "\n",
    "    plt.savefig(projectdir + 'windows/HEATMAP_'+cat+'_values_per_window__BuRd.eps')\n",
    "    plt.show()\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "windows2values = pd.read_csv(all_values_per_window_fname, sep = '\\t', header = 0)\n",
    "windows2values.drop('Supercontig', axis=1, inplace=True)\n",
    "windows2values.drop('start', axis=1, inplace=True)\n",
    "windows2values.drop('end', axis=1, inplace=True)\n",
    "\n",
    "exclude = ['SNPs_VCG030', 'SNPs_CladeIII']\n",
    "names.remove('SNPs_VCG030')\n",
    "names.remove('SNPs_CladeIII')\n",
    "\n",
    "for prop in exclude:\n",
    "    windows2values.drop(prop, axis=1, inplace=True)\n",
    "print(windows2values)\n",
    "# Pandas deals with missing values correctly, hence we will use pandas tp calculate correlations\n",
    "# min_periods is minimum number of values in a column\n",
    "corr_df           = windows2values.corr(method='spearman', min_periods = 20)\n",
    "print(corr_df)\n",
    "similarity_matrix = corr_df.as_matrix()\n",
    "\n",
    "#convert this similarity matrix into a distance matrix that is suitable for scipy.cluster.hierarchy\n",
    "distance_matrix   = similarity_matrix_2D__to__distance_matrix_1D(similarity_matrix)\n",
    "\n",
    "row_linkage = hierarchy.linkage(distance_matrix, method='average')\n",
    "#print(row_linkage)\n",
    "\n",
    "clst = sns.clustermap(similarity_matrix, row_linkage=row_linkage, col_linkage = row_linkage, vmin = -1.0, vmax = 1.0, cmap = 'RdBu')#RdYlGn')\n",
    "\n",
    "# get correct labeling\n",
    "name_index2name = {}\n",
    "for name_index, name in enumerate(names):\n",
    "    if name not in exclude:\n",
    "        name_index2name[name_index] = name\n",
    "    \n",
    "xlabels_as_index = []\n",
    "for textobject in clst.ax_heatmap.get_xticklabels():\n",
    "    xlabels_as_index.append(int(textobject.get_text()))\n",
    "print(xlabels_as_index)\n",
    "\n",
    "xaxis_labels = []\n",
    "for li in xlabels_as_index:\n",
    "    xaxis_labels.append(name_index2name[li])\n",
    "clst.ax_heatmap.set_xticklabels(xaxis_labels, rotation = 'vertical')\n",
    "\n",
    "ylabels_as_index = []\n",
    "for textobject in clst.ax_heatmap.get_yticklabels():\n",
    "    ylabels_as_index.append(int(textobject.get_text()))\n",
    "print(ylabels_as_index)\n",
    "\n",
    "yaxis_labels = []\n",
    "for li in ylabels_as_index:\n",
    "    yaxis_labels.append(name_index2name[li])\n",
    "clst.ax_heatmap.set_yticklabels(yaxis_labels, rotation = 'horizontal')\n",
    "      \n",
    "        \n",
    "plt.savefig(projectdir + 'windows/HEATMAP_values_per_window__RdBu_noSNPs.eps')#YlGn.eps')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
